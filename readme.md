# Task-irrelevant valence-preferred colors boost visual search for a singleton-shape target

This repository contains the data and analysis scripts for the paper "Task-irrelevant valence-preferred colors boost visual search for a singleton-shape target" by Miloš Stanković, Hermann J. Müller, and Zhuanghua Shi. 

## Abstract
Some studies have suggested that emotion-associated features might drive attentional capture. Yet, valence-dependent distractor interference has proven hard to demonstrate, possibly because individuals’ color-valence preferences are ignored in the standard, averaged reaction-time (RT) measures. To investigate this, we adopted (variants of) the valence-driven attentional-capture paradigm: an association phase, in which two alternative target colors, red vs. green, were paired with emotionally neutral vs. positive feedback photographs, was followed by a test phase requiring search for a pop-out shape target in the presence vs. absence of a task-irrelevant emotion-associated color; in Experiments 1 and 2, this color could appear (only) in a distractor, and in Experiment 3 in the target. When examining the standard, averaged RT measures, we found no significant valence association or valence-modulated attentional capture. However, correlational analyses revealed a consistent positive relationship between individual participants’ color-valence preference in the association phase and their valence-based effect in the test phase, in all three experiments. While this relationship held for all participants, the majority preferred red over green, leading to marked color-related asymmetries in the average measures. Importantly, the presence of the valence-preferred color anywhere in the test display facilitated RTs. This was the case even when the color appeared in one of the distractors, at variance with this distractor capturing attention. This suggests that, while the task-irrelevant color signals were registered pre-attentively and boosted performance, likely by raising the general (non-spatial) alertness level, they could be kept out of attentional-priority computation to prevent inadvertent attentional capture. 

## Data

The data are stored in the `data` folder with `raw.RData`. 

## Analysis

The analysis is performed in R, and the scripts can be found in `analysis_journal.rmd`. 
The generated figures are stored in the `figures` folder and the output can be found in `analysis_journal.html`.
